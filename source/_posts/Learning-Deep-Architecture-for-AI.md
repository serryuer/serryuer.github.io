---
title: Learning Deep Architecture for AI
date: 2019-04-13 20:01:49
tags:

---

## 摘要

理论结果表明为了学习更加复杂和更加高层次的表示（比如文本、视觉、声音等），我们需要学习更深的架构。深层架构包括多层非线性的操作，比如隐藏神经元，但是在深层架构的参数空间中寻找最优解是一个很难优化的问题，一些学习算法，比如用于深度信念网络学的Wake-Sleep算法，可以解决这个问题。这篇文章就是讨论学习深层架构的算法。

## 介绍

目前的学习算法还只能在非常有限的场景下发挥作用，为了解决复杂的问题，我们通常将其分解成很多的子问题，分而治之，为了识别出一张图片中的信息，我们可以从识别图片中的边开始，然后是复杂一点的形状，比如矩形、三角形，再然后可以识别一些抽象的类别，比如猫和狗等，把所有这些识别出来的信息加在一起就可以更好的识别出这张图片对应的场景、信息。我们把学习系统的原始输入看作是一个高维的实体，由许多观察到的变量组成，这些变量由未知的复杂统计关系联系起来。例如，利用3-D物体和光学的三维几何知识，我们可以将基础物理和几何因素(如位置、方向、物体的照明)的微小变化与图像中所有像素的像素强度变化联系起来。如果机器可以识别出这些特征并且能够解释它们之间的关系，以及如何根据这些特征生成对应的数据，我们就可以说机器理解了这些特征所组成的特征空间。

## 浅层结构的理论限制

有一些函数不能被浅层结构有效的表达，因为可调整元素的数量。具体的说一个可以被k层结构表示的函数如果要用k-1层结构表示需要增加指数级的计算元素。

## 局部 vs 非局部泛化

